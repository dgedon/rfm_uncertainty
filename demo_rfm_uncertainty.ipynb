{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "291bb2a9-b69f-4261-9683-12696d472bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import gpytorch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67e39068-cedc-4431-9b1a-0c73b3ba1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed everything\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5729e46-e1a1-47e0-95a4-20c9eb776c31",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "Here, we load data from the tabular benchmark suite https://github.com/LeoGrin/tabular-benchmark \n",
    "\n",
    "ids from https://arxiv.org/pdf/2207.08815.pdf, appendix A.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23e28b34-9f4e-49d0-bd55-0b4fdbf15d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset_idx = 3\n",
    "type_ids = {\n",
    "    44132,  # 0 cpu-act\n",
    "    44133,  # 1 pol\n",
    "    44134,  # 2 elevators\n",
    "    44135,  # 3 isolet\n",
    "    44136,  # 4 wine-quality\n",
    "    44137,  # 5 Ailerons\n",
    "    44138,  # 6 houses\n",
    "    44139,  # 7 house-16H\n",
    "    44141,  # 8 Brazilian-houses\n",
    "    44142,  # 9 Bike-Sharing-Demand\n",
    "    44144,  # 10 house-sales\n",
    "    44145,  # 11 sulfur\n",
    "    44147,  # 12 MiamiHousing2016\n",
    "    44148,  # 13 superconduct\n",
    "    44025,  # 14 california\n",
    "    44026,  # 15 fifa\n",
    "}\n",
    "dataset_id = list(type_ids)[dataset_idx]\n",
    "dataset = openml.datasets.get_dataset(dataset_id)\n",
    "# dataset_name = dataset.name\n",
    "X, y, _, _ = dataset.get_data(dataset_format='dataframe', target=dataset.default_target_attribute)\n",
    "X, y = X.values, y.values.astype(np.float32)\n",
    "\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "\n",
    "# to torch and device\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32, device=device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335b9f5-98fe-4f06-8e19-499331d0eaa5",
   "metadata": {},
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b250bcf2-472d-46c8-9da5-f477d9f8c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchStandardScaler:\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.std_ = None\n",
    "    def fit(self, X):\n",
    "        self.mean_ = X.mean(dim=0)\n",
    "        self.std_ = X.std(dim=0)\n",
    "    def transform(self, X):\n",
    "        return (X - self.mean_) / self.std_\n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "    def inverse_transform(self, X):\n",
    "        return X * self.std_ + self.mean_\n",
    "    def inverse_transform_std(self, X):\n",
    "        return X * self.std_\n",
    "\n",
    "Xscaler = TorchStandardScaler()\n",
    "yscaler = TorchStandardScaler()\n",
    "\n",
    "X_train = Xscaler.fit_transform(X_train)\n",
    "X_test = Xscaler.transform(X_test)\n",
    "\n",
    "y_train = yscaler.fit_transform(y_train)\n",
    "y_test = yscaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a9595-8629-4cf3-aa3d-8c77ffe5f4b7",
   "metadata": {},
   "source": [
    "# Define the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8fdba20-1d84-4835-a0f0-d1f4dd2575df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_gp import ExpMahalanobisDistanceKernel\n",
    "from recursive_feature_machine import LaplaceRFM\n",
    "\n",
    "\n",
    "# define the GP model\n",
    "class GPLaplaceMahalanobis(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, weight_matrix):\n",
    "        super(GPLaplaceMahalanobis, self).__init__(train_x, train_y, likelihood)\n",
    "        self.weight_matrix = weight_matrix.to(train_x)\n",
    "\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            ExpMahalanobisDistanceKernel(\n",
    "                weight_matrix=self.weight_matrix,\n",
    "                squared=False,\n",
    "                ard_num_dims=1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "rfm_reg = 1e-3\n",
    "rfm_ridge = 1e-7\n",
    "rfm_diag = False\n",
    "\n",
    "# define the RFM model\n",
    "model_rfm = LaplaceRFM(\n",
    "    bandwidth=1,\n",
    "    device=device,\n",
    "    reg=rfm_reg,\n",
    "    ridge=rfm_ridge,\n",
    "    verbose=False,\n",
    "    diag=rfm_diag,\n",
    "    centering=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71457048-4b29-4084-a2c2-294842ad5081",
   "metadata": {},
   "source": [
    "# Train the RFM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d906da35-c87a-4299-94bd-8cad8819ca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 224 ms, sys: 56.1 ms, total: 280 ms\n",
      "Wall time: 280 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_rfm.fit(\n",
    "    (X_train, y_train), (X_test, y_test),\n",
    "    loader=False,iters=5,\n",
    "    classif=False,\n",
    ")\n",
    "\n",
    "weight_matrix = model_rfm.M\n",
    "del model_rfm\n",
    "\n",
    "# define the GP model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model_gp = GPLaplaceMahalanobis(X_train, y_train, likelihood, weight_matrix)\n",
    "\n",
    "# move to device\n",
    "likelihood = likelihood.to(device)\n",
    "model_gp = model_gp.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a620b2e-e10e-4450-94e8-f695ee5b1b51",
   "metadata": {},
   "source": [
    "# Train the GP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99bda218-4ba7-482b-b5f9-c4a902c1b7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6277768af33149eab94e9ecd9d709aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training GP:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.22 s, sys: 1.46 s, total: 9.67 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "lr = 0.05\n",
    "n_epochs = 250\n",
    "\n",
    "\n",
    "def train_gp():\n",
    "    model_gp.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(model_gp.parameters(), lr=0.1)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=1e-7)\n",
    "\n",
    "    # loss, the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model_gp)\n",
    "\n",
    "    with trange(n_epochs, desc='Training GP') as pbar:\n",
    "        for _ in pbar:\n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            # Output from model\n",
    "            output = model_gp(X_train)\n",
    "            # Calc loss and backprop gradients\n",
    "            loss = -mll(output, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "# train the GP model\n",
    "%time train_gp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f286f4ff-1b45-44be-a7ff-631fb98f5b22",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b57ba90b-232b-4db7-8336-511ca1c3e5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.6848392486572266\n",
      "NLL: 2.382169723510742\n"
     ]
    }
   ],
   "source": [
    "model_gp.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    preds = likelihood(model_gp(X_test))\n",
    "\n",
    "# unnormalize\n",
    "y_pred_mean = yscaler.inverse_transform(preds.mean)\n",
    "y_pred_std = yscaler.inverse_transform_std(preds.stddev)\n",
    "y_test = yscaler.inverse_transform(y_test)\n",
    "\n",
    "# calculate the RMSE\n",
    "rmse = torch.sqrt(torch.mean((y_pred_mean - y_test) ** 2, dim=-1))\n",
    "print(f'RMSE: {rmse}')\n",
    "# calculate the NLL\n",
    "covariance_matrix = torch.diag_embed(y_pred_std ** 2)\n",
    "mvn = torch.distributions.MultivariateNormal(y_pred_mean, covariance_matrix)\n",
    "nll = -mvn.log_prob(y_test) / y_test.shape[0]\n",
    "print(f'NLL: {nll}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
